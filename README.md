# üèòÔ∏è EduStream: Multirepo Architecture Demo

Este repositorio demuestra una implementaci√≥n pr√°ctica de una arquitectura **Multirepo** (Desacoplada) para un sistema de Machine Learning end-to-end.

‚ö†Ô∏è **NOTA IMPORTANTE:**
Para fines educativos, este repositorio contiene **tres carpetas que simulan ser repositorios totalmente independientes**.
En un escenario real, cada carpeta (`repo-ml`, `repo-api`) vivir√≠a en su propio repositorio de GitHub y el `artifact-registry` ser√≠a un servicio de almacenamiento en la nube (como AWS S3, Azure Blob Storage o Google Cloud Storage).

---

## üó∫Ô∏è Mapa del "Vecindario" (Estructura)

En esta arquitectura, los equipos viven en "casas" separadas y no tienen llaves para entrar a la casa del otro.

### 1. `repo-ml/` (El Productor) üç≥
* **Rol:** Equipo de Data Science.
* **Misi√≥n:** Entrenar modelos y **publicarlos**.
* **Regla de Oro:** No sabe que existe una API. Su trabajo termina cuando sube el archivo `.pkl` al Registro.
* **Simulaci√≥n:** Al ejecutar su c√≥digo, "sube" un archivo a la carpeta compartida.

### 2. `repo-api/` (El Consumidor) üçΩÔ∏è
* **Rol:** Equipo de Backend.
* **Misi√≥n:** Leer el modelo publicado y usarlo para predecir.
* **Regla de Oro:** No tiene acceso al c√≥digo de entrenamiento ni a los datos originales. Solo conf√≠a en los archivos que aparecen en el Registro.

### 3. `artifact-registry/` (El Intermediario) ‚òÅÔ∏è
* **Rol:** Almacenamiento Central (Simulaci√≥n de la Nube).
* **Misi√≥n:** Es el √∫nico punto de contacto entre los dos equipos. Funciona como un "buz√≥n de entrega".

---

## üöÄ Gu√≠a de Ejecuci√≥n (Roleplay)

Para entender esta arquitectura, debes actuar como si fueras dos personas distintas en momentos distintos. Sigue estos pasos en tu terminal:

### Paso 0: Clonar el Proyecto
```bash
git clone [https://github.com/TU_USUARIO/edustream-multirepo-demo.git](https://github.com/TU_USUARIO/edustream-multirepo-demo.git)
cd edustream-multirepo-demo
```
### Paso 1: Rol de Cient√≠fico de Datos (Train & Deploy)
Primero, ponte el sombrero de Data Scientist. Debes entrar a tu repositorio para trabajar.

```Bash
# 1. Entramos a la "oficina" de ML
cd repo-ml

# 2. Ejecutamos el pipeline
# Este script entrena el modelo y lo COPIA (Deploy) al registry
python train_publish.py
```

## ‚úÖ Resultado Esperado: 
Ver√°s un mensaje de DEPLOY EXITOSO. Si revisas la carpeta artifact-registry, ver√°s que ha aparecido un archivo churn_model_v2.pkl.

### Paso 2: Rol de Desarrollador Backend (Consume)
Ahora c√°mbiate de sombrero. Sal de la oficina de ML y entra a la de la API. La API no sabe c√≥mo se cocin√≥ el modelo, solo lo consume.

```Bash
# 1. Salimos de ML y entramos a API
cd ..
cd repo-api

# 2. Ejecutamos el servidor de inferencia
python serve_consume.py
```

##‚úÖ Resultado Esperado: 
La API leer√° el archivo desde el artifact-registry y confirmar√° que el modelo v2.0 est√° cargado y listo.

## üß™ Experimento de Desacoplamiento
Para demostrar la independencia de los sistemas, intenta lo siguiente:

Borra el archivo .pkl de la carpeta artifact-registry.

Intenta ejecutar la API (python serve_consume.py).

Resultado: Fallar√° con un error controlado.

## Lecci√≥n: 
A diferencia del Monorepo, si no hay un "Release" expl√≠cito en el medio (el archivo en el registry), la API no puede funcionar, incluso si el c√≥digo de ML est√° perfecto en su propia carpeta.

| Caracter√≠stica | Monorepo (La Casa Familiar) | Multirepo (Este Ejemplo) |
| :--- | :--- | :--- |
| **Acceso a C√≥digo** | La API puede importar funciones de ML directamente. | **Prohibido.** Aislamiento total. |
| **Compartir Modelos** | Leyendo la carpeta de al lado (Ruta relativa). | **Publicando** en un Registry externo (S3/Artifactory). |
| **Coordinaci√≥n** | Impl√≠cita (cambios inmediatos). | **Expl√≠cita** (versiones y contratos). |
| **Independencia** | Baja (Si rompes Core, rompes todo). | Alta (Cada equipo tiene su ciclo de vida). |

üìù Licencia
Este proyecto es parte del material educativo de Soy Henry - Carrera de Data Science - M√≥dulo 5.
